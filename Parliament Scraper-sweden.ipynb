{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "4) Sweden\n",
    "===========\n",
    "\n",
    "Sessions are listed in http://data.riksdagen.se/data/anforanden/\n",
    "\n",
    "This script will create a folder with a subfolder for each year extracted. Data from 1993 to 2016.\n",
    "\n",
    "The files have each speech of each member in each session. It would be nice if someone went to the trouble of merging them altogether and create a complete session (which for some reason is not available online)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1 out of 23 ...\n",
      "Downloading 2 out of 23 ...\n",
      "Downloading 3 out of 23 ...\n",
      "Downloading 4 out of 23 ...\n",
      "Downloading 5 out of 23 ...\n",
      "Downloading 6 out of 23 ...\n",
      "Downloading 7 out of 23 ...\n",
      "Downloading 8 out of 23 ...\n",
      "Downloading 9 out of 23 ...\n",
      "Downloading 10 out of 23 ...\n",
      "Downloading 11 out of 23 ...\n",
      "Downloading 12 out of 23 ...\n",
      "Downloading 13 out of 23 ...\n",
      "Downloading 14 out of 23 ...\n",
      "Downloading 15 out of 23 ...\n",
      "Downloading 16 out of 23 ...\n",
      "Downloading 17 out of 23 ...\n",
      "Downloading 18 out of 23 ...\n",
      "Downloading 19 out of 23 ...\n",
      "Downloading 20 out of 23 ...\n",
      "Downloading 21 out of 23 ...\n",
      "Downloading 22 out of 23 ...\n",
      "Downloading 23 out of 23 ...\n",
      "Great Success!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "import zipfile, io\n",
    "\n",
    "url = 'http://data.riksdagen.se/data/anforanden/'\n",
    "page = requests.get(url);\n",
    "soup = bs4.BeautifulSoup(page.text,'html.parser')\n",
    "\n",
    "links = []\n",
    "for element in soup.findAll('a'):\n",
    "    if 'json.zip' in element['href']:\n",
    "        links.append('http:'+element['href'])\n",
    "\n",
    "for idx, link in enumerate(links):\n",
    "    print(\"Downloading\",idx+1,\"out of\",len(links),\"...\")\n",
    "    try:\n",
    "        year = link.split('.json.zip')[0].rsplit('-',1)[1]\n",
    "        year = year[:4] + '-' + year[4:]\n",
    "        r = requests.get(link)\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall('files/'+year)\n",
    "    except:\n",
    "        print(\"Failed at downloading/extracting:\",link)\n",
    "        pass\n",
    "\n",
    "print(\"Great Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
